{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Тут мы усталеўваем неабходныя пакетыдля запуску мадэлі"
      ],
      "metadata": {
        "id": "Mc62_J74Gh2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers torch"
      ],
      "metadata": {
        "id": "QiDkPj5pmZuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далей пераходзім да  самаго нашага скрыпта.\n",
        "Падстаўляем ваш уласны ключ.\n",
        "Дадаем неабходны нам промпт з тэкстам, дэталева апісваючым што неабходна намаляваць.\n",
        "\n",
        "\n",
        "Усталёўваем неабходную нам шырыню праз параметры  height ды weight.\n",
        "Усталеўваем колькасць апрацовак малюнкаў праз num_inference_steps (чым боль тым лепш але вельмі шмат -будзе вельмі доўга апрацоўвацца, таму можна браць 20-30. па змаўчанню -  50)\n",
        "Праметр guidance_scale задае наколькі мадэль будзе \"свавольнічаць\".\n",
        "guidance_scale=3.5: Мадэль будзе арыентавацца на ваш запыт, але з некаторымі крэатыўнымі адхіленнямі.\n",
        "guidance_scale=7.5: Вынік будзе больш дакладна адпавядаць апісанню.\n",
        "guidance_scale=15.0: Мадэль можа перашчыраваць і стварыць менш натуральны вынік.\n"
      ],
      "metadata": {
        "id": "-LKPqJRVGwdH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuHw8RRHlt6W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from diffusers import FluxPipeline  # Assuming the pipeline is from flux_pipeline\n",
        "import torch\n",
        "from datetime import datetime\n",
        "\n",
        "# Your Hugging Face token\n",
        "os.environ[\"HF_TOKEN\"] = \"hf_key\"\n",
        "\n",
        "pipe = FluxPipeline.from_pretrained(\"black-forest-labs/FLUX.1-dev\", torch_dtype=torch.bfloat16)\n",
        "pipe.enable_sequential_cpu_offload()\n",
        "pipe.vae.enable_slicing()\n",
        "pipe.vae.enable_tiling()\n",
        "\n",
        "prompt = \"Knights are marching in formation with swords and shields, dressed in various dark armors with closed helmets, in winter. Two soldiers are mounted on horses. They wear white cloaks with red crosses. They are returning to a nearby castle as snow falls. The atmosphere is gloomy, with ravens circling in the sky.\"\n",
        "print(f\"Prompt: {len(prompt)} characters\")\n",
        "out = pipe(\n",
        "    prompt=prompt,\n",
        "    height=512,\n",
        "    width=512*2,\n",
        "    guidance_scale=3.5,  # Increase to make the guidance more prominent\n",
        "    num_inference_steps=30, # Number of inference steps\n",
        "    max_sequence_length=512, # Maximum length of the prompt\n",
        "    generator=torch.Generator(device='cuda').manual_seed(0),\n",
        ").images[0]\n",
        "\n",
        "# Generate a unique filename with a timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_filename = f\"knights_white_horses_{timestamp}.png\"\n",
        "\n",
        "out.save(output_filename)\n",
        "print(f\"Image saved as {output_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У выніку атрымаем выяву у папцы каля нашага скрыпта.  "
      ],
      "metadata": {
        "id": "T80WGcAMJrxd"
      }
    }
  ]
}
